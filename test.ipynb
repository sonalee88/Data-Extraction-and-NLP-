{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPd7C57OBg5V2rOpuRcwkeL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Data Extraction and NLP**"],"metadata":{"id":"97drcqr3vrGh"}},{"cell_type":"markdown","source":["The objective of this assignment is to extract textual data articles from the given URL and perform text analysis to compute variables that are explained below."],"metadata":{"id":"ssICpe3RvxV9"}},{"cell_type":"code","source":["!pip install pandas requests beautifulsoup4 nltk textblob syllapy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCx0zV8Dw0Wm","executionInfo":{"status":"ok","timestamp":1714577176219,"user_tz":-330,"elapsed":7850,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}},"outputId":"ee641323-22fa-4644-80b3-af0d29cff1f1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n","Collecting syllapy\n","  Downloading syllapy-0.7.2-py3-none-any.whl (24 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Installing collected packages: syllapy\n","Successfully installed syllapy-0.7.2\n"]}]},{"cell_type":"code","source":["# Download necessary NLTK resources\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('vader_lexicon')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OU9wDRHl0KmY","executionInfo":{"status":"ok","timestamp":1714578050340,"user_tz":-330,"elapsed":1539,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}},"outputId":"791b43c0-4955-459e-88bd-edb0bb9b6625"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"KJwqQdXZvfjP","executionInfo":{"status":"ok","timestamp":1714577181539,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}}},"outputs":[],"source":["import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup\n","import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.corpus import stopwords\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","from textblob import TextBlob\n","import re\n","import syllapy"]},{"cell_type":"code","source":["# Download VADER lexicon\n","nltk.download('vader_lexicon')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNUMD3MIyYqR","executionInfo":{"status":"ok","timestamp":1714577622554,"user_tz":-330,"elapsed":10,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}},"outputId":"c32360aa-4d03-4ce9-a971-75cb5a9aa6c3"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":14},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Load input data\n","input_df = pd.read_excel(\"/content/Input.xlsx\")"],"metadata":{"id":"Ytd0YvoHwwxV","executionInfo":{"status":"ok","timestamp":1714577220247,"user_tz":-330,"elapsed":921,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Function to extract text from URL\n","def extract_text(url):\n","    try:\n","        response = requests.get(url)\n","        soup = BeautifulSoup(response.content, 'html.parser')\n","        article = soup.find('article')\n","        text = \" \".join([p.get_text() for p in article.find_all('p')])\n","        return text\n","    except Exception as e:\n","        print(f\"Error extracting text from {url}: {e}\")\n","        return None"],"metadata":{"id":"CvvrFCsSw8QC","executionInfo":{"status":"ok","timestamp":1714577234679,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Function to calculate sentiment scores\n","def calculate_sentiment(text):\n","    sia = SentimentIntensityAnalyzer()\n","    polarity_score = sia.polarity_scores(text)['compound']\n","    subjectivity_score = TextBlob(text).sentiment.subjectivity\n","    positive_score = len(re.findall(r'\\b(good|great|excellent|positive)\\b', text, flags=re.IGNORECASE))\n","    negative_score = len(re.findall(r'\\b(bad|poor|negative)\\b', text, flags=re.IGNORECASE))\n","    return positive_score, negative_score, polarity_score, subjectivity_score"],"metadata":{"id":"MM3Nr-6bxFJB","executionInfo":{"status":"ok","timestamp":1714577294216,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Function to calculate readability metrics\n","def calculate_readability(text):\n","    sentences = sent_tokenize(text)\n","    words = word_tokenize(text)\n","    total_words = len(words)\n","    total_sentences = len(sentences)\n","    avg_sentence_length = total_words / total_sentences\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    filtered_words = [word for word in words if word.lower() not in stop_words]\n","    # Count complex words\n","    complex_words = [word for word in filtered_words if syllapy.count(word) > 2]\n","    complex_word_count = len(complex_words)\n","    percentage_complex_words = (complex_word_count / total_words) * 100\n","    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n","    avg_word_length = sum(len(word) for word in filtered_words) / len(filtered_words)\n","\n","    return avg_sentence_length, percentage_complex_words, fog_index, avg_word_length"],"metadata":{"id":"mVQFiczSxH7W","executionInfo":{"status":"ok","timestamp":1714577364222,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Function to count personal pronouns\n","def count_personal_pronouns(text):\n","    personal_pronouns = len(re.findall(r'\\b(I|we|my|ours|us)\\b', text, flags=re.IGNORECASE))\n","    return personal_pronouns\n",""],"metadata":{"id":"Wce15ZrfxQ0p","executionInfo":{"status":"ok","timestamp":1714577375349,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Function to count syllables per word\n","def count_syllables_per_word(text):\n","    words = word_tokenize(text)\n","    syllable_count = sum(syllapy.count(word) for word in words)\n","    syllable_per_word = syllable_count / len(words)\n","    return syllable_per_word"],"metadata":{"id":"ssFZYIjhxRLD","executionInfo":{"status":"ok","timestamp":1714577383698,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Function to process each URL and compute variables\n","def process_url(url_id, url):\n","    text = extract_text(url)\n","    if text:\n","        positive_score, negative_score, polarity_score, subjectivity_score = calculate_sentiment(text)\n","        avg_sentence_length, percentage_complex_words, fog_index, avg_word_length = calculate_readability(text)\n","        personal_pronouns = count_personal_pronouns(text)\n","        syllable_per_word = count_syllables_per_word(text)\n","\n","        return {\n","            \"URL_ID\": url_id,\n","            \"URL\": url,\n","            \"POSITIVE SCORE\": positive_score,\n","            \"NEGATIVE SCORE\": negative_score,\n","            \"POLARITY SCORE\": polarity_score,\n","            \"SUBJECTIVITY SCORE\": subjectivity_score,\n","            \"AVG SENTENCE LENGTH\": avg_sentence_length,\n","            \"PERCENTAGE OF COMPLEX WORDS\": percentage_complex_words,\n","            \"FOG INDEX\": fog_index,\n","            \"AVG NUMBER OF WORDS PER SENTENCE\": len(word_tokenize(text)) / len(sent_tokenize(text)),\n","            \"COMPLEX WORD COUNT\": len([word for word in word_tokenize(text) if syllapy.count(word) > 2]),\n","            \"WORD COUNT\": len(word_tokenize(text)),\n","            \"SYLLABLE PER WORD\": syllable_per_word,\n","            \"PERSONAL PRONOUNS\": personal_pronouns,\n","            \"AVG WORD LENGTH\": avg_word_length\n","        }\n","    else:\n","        return None\n"],"metadata":{"id":"kYZm4tIUxRq7","executionInfo":{"status":"ok","timestamp":1714577398746,"user_tz":-330,"elapsed":1448,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Process each URL and compute variables\n","output_data = []\n","for index, row in input_df.iterrows():\n","    url_id = row['URL_ID']\n","    url = row['URL']\n","    data = process_url(url_id, url)  # This line is causing the issue\n","    if data:\n","        output_data.append(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2UiolP4zwur","executionInfo":{"status":"ok","timestamp":1714578115073,"user_tz":-330,"elapsed":55496,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}},"outputId":"0e2c856f-f3c8-4668-9a70-d2edf6776c06"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Error extracting text from https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/: 'NoneType' object has no attribute 'find_all'\n","Error extracting text from https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/: 'NoneType' object has no attribute 'find_all'\n"]}]},{"cell_type":"code","source":["# Create DataFrame for output data\n","output_df = pd.DataFrame(output_data)"],"metadata":{"id":"9GLZgdkwxwSn","executionInfo":{"status":"ok","timestamp":1714578147211,"user_tz":-330,"elapsed":446,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Save output to Excel file\n","output_df.to_excel(\"output.xlsx\", index=False)"],"metadata":{"id":"iyglRqb-x2v3","executionInfo":{"status":"ok","timestamp":1714578151155,"user_tz":-330,"elapsed":491,"user":{"displayName":"Sonali Kumari","userId":"08012356860547186654"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mbncsw5pzz0T"},"execution_count":null,"outputs":[]}]}